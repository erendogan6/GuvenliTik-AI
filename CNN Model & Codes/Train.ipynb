{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c6ec1b-18a3-4ff0-b9ec-fdd4102b8542",
   "metadata": {
    "gather": {
     "logged": 1702416422507
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np  # Used for numerical operations like array manipulation\n",
    "import pandas as pd  # Pandas library for data manipulation and analysis\n",
    "from keras.layers import BatchNormalization  # Normalizes the inputs to a layer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  # Tokenizes texts into tokens\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences  # Pads sequences to the same length\n",
    "from tensorflow.keras.models import Sequential  # Sequential model for linear stack of layers\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense  # Various layers for model construction\n",
    "from keras.layers import Dropout  # Dropout layer to reduce overfitting\n",
    "from sklearn.preprocessing import LabelEncoder  # Encodes labels to normalized format\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint  # Callbacks for controlling the training process\n",
    "import seaborn as sns  # Visualization library based on matplotlib\n",
    "import matplotlib.pyplot as plt  # Basic library for plotting graphs\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix  # Metrics for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccded88-d40f-4f2b-8302-cd3731a7892f",
   "metadata": {
    "gather": {
     "logged": 1702416424511
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Function to load dataset\n",
    "def load_dataset(file_path):\n",
    "    # Load a CSV file into a DataFrame without a header and with quotes around strings\n",
    "    df = pd.read_csv(file_path, header=None, quotechar='\"')\n",
    "    return df\n",
    "\n",
    "# Load training and testing data\n",
    "train_df = load_dataset('updated_train.csv')  # Load the training data\n",
    "test_df = load_dataset('updated_test.csv')  # Load the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f2600d-7556-45d1-938f-0a8cb574156a",
   "metadata": {
    "gather": {
     "logged": 1702416448315
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Prepare URL and label data for training and testing\n",
    "train_urls = train_df[1].tolist()  # Extract URLs from training data\n",
    "train_labels = train_df[0].tolist()  # Extract labels from training data\n",
    "test_urls = test_df[1].tolist()  # Extract URLs from testing data\n",
    "test_labels = test_df[0].tolist()  # Extract labels from testing data\n",
    "\n",
    "# Tokenize the URL data\n",
    "tokenizer = Tokenizer(char_level=True)  # Initialize a tokenizer that works at the character level\n",
    "tokenizer.fit_on_texts(train_urls)  # Fit the tokenizer on the training URLs\n",
    "\n",
    "# Convert URLs to sequences of integers\n",
    "train_sequences = tokenizer.texts_to_sequences(train_urls)  # Convert training URLs to sequences\n",
    "test_sequences = tokenizer.texts_to_sequences(test_urls)  # Convert testing URLs to sequences\n",
    "\n",
    "# Find the maximum sequence length for padding\n",
    "max_length = max(max(len(s) for s in train_sequences), max(len(s) for s in test_sequences))  # Find max length\n",
    "\n",
    "# Pad the sequences to ensure uniform length\n",
    "train_data = pad_sequences(train_sequences, maxlen=max_length)  # Pad training sequences\n",
    "test_data = pad_sequences(test_sequences, maxlen=max_length)  # Pad testing sequences\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()  # Initialize the label encoder\n",
    "train_labels = label_encoder.fit_transform(train_labels)  # Fit and transform training labels\n",
    "test_labels = label_encoder.transform(test_labels)  # Transform testing labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c79499b-2223-40a6-9206-60e428042395",
   "metadata": {
    "gather": {
     "logged": 1702416448989
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Model building\n",
    "from keras.optimizers import Adam  # Import the Adam optimizer\n",
    "model = Sequential()  # Create a sequential model\n",
    "# Add embedding layer\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=50, input_length=max_length))\n",
    "# Add convolution layers\n",
    "model.add(Conv1D(filters=128, kernel_size=6, activation='relu'))\n",
    "model.add(Conv1D(filters=128, kernel_size=6, activation='relu'))\n",
    "# Add global max pooling layer\n",
    "model.add(GlobalMaxPooling1D())\n",
    "# Add dense layer for output\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(lr=0.0001)  # Initialize Adam optimizer with a learning rate\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])  # Compile the model\n",
    "model.summary()  # Print the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3349f9e-989f-48cf-8fc6-57caed5c8f8c",
   "metadata": {
    "gather": {
     "logged": 1702416449030
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Callbacks for training\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',  # Monitor validation accuracy\n",
    "    mode='max',  # Mode is max because we want to maximize accuracy\n",
    "    patience=8,  # Number of epochs with no improvement after which training will be stopped\n",
    "    min_delta=0.00009,  # Minimum change to qualify as an improvement\n",
    "    restore_best_weights=True,  # Restore model weights from the epoch with the best value of the monitored quantity\n",
    "    verbose=1  # Verbosity mode\n",
    ")\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'best_model.keras',  # File path to save the model\n",
    "    monitor='val_accuracy',  # Monitor validation accuracy\n",
    "    mode='max',  # Mode is max because we want to maximize accuracy\n",
    "    save_best_only=True,  # Save only when the monitored quantity has improved\n",
    "    verbose=1  # Verbosity mode\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e686e4b2",
   "metadata": {
    "gather": {
     "logged": 1702538322108
    },
    "run_control": {
     "frozen": false
    }
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_data, train_labels, epochs=100, validation_data=(test_data, test_labels), batch_size=32,\n",
    "          callbacks=[early_stopping, model_checkpoint], verbose=1)  # Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fee1ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the training history\n",
    "import json\n",
    "history_dict = history.history  # Get history data from the model\n",
    "json.dump(history_dict, open(\"history.json\", 'w'))  # Save history data to a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bc6034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')  # Plot training loss\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')  # Plot validation loss\n",
    "plt.title('Training and Validation Loss')  # Title of the plot\n",
    "plt.ylabel('Loss')  # Y-axis label\n",
    "plt.xlabel('Epoch')  # X-axis label\n",
    "plt.legend()  # Add legend\n",
    "plt.show()  # Display the plot\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')  # Plot training accuracy\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')  # Plot validation accuracy\n",
    "plt.title('Training and Validation Accuracy')  # Title of the plot\n",
    "plt.ylabel('Accuracy')  # Y-axis label\n",
    "plt.xlabel('Epoch')  # X-axis label\n",
    "plt.legend()  # Add legend\n",
    "plt.show()  # Display the plot\n",
    "\n",
    "# Evaluate model performance\n",
    "predictions = model.predict(test_data)  # Predict on test data\n",
    "predictions = (predictions > 0.5).astype(\"int32\")  # Convert predictions to binary\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision = precision_score(test_labels, predictions)  # Calculate precision\n",
    "recall = recall_score(test_labels, predictions)  # Calculate recall\n",
    "f1 = f1_score(test_labels, predictions)  # Calculate F1 score\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(test_labels, predictions)  # Calculate confusion matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')  # Plot confusion matrix using seaborn\n",
    "plt.xlabel('Predicted')  # X-axis label\n",
    "plt.ylabel('True')  # Y-axis label\n",
    "plt.title('Confusion Matrix')  # Title of the plot\n",
    "plt.show()  # Display the plot"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
